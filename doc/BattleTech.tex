% 
% Practica ICO
% ------------------
% Ingeniería del Conocimento
% Universidad de Granada
% 
% Autor:
% - María Carrasco Rodríguez
% 

\documentclass[a4paper,12pt,oneside]{book}
\usepackage[spanish]{babel}
\usepackage{graphicx}
\usepackage{ucs}
\usepackage{listings}
\usepackage[utf8]{inputenc}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{hyperref}
\usepackage{url}
\usepackage{multirow}
\usepackage{listings}  
\lstset{language=Python,commentstyle=\emph}
\usepackage{color} 
\usepackage{colortbl}

\usepackage{phdthesis}



% opening
\title{Jugador Inteligente}
\author{María Carrasco Rodríguez \\
  Francisco Manuel Herrero Pérez}
\date{Curso 2009/10}
\parskip = 7 pt

\makeindex

\begin{document}
\begin{titlepage}
  \parskip = 6pt
  \null\vfil
  \hrule height 2pt
  \begin{center}
    \huge \textsf{\emph{ BattleTech}
      \\ \textbf{ Jugador Inteligente }}
    % \large \textit{\@subtitle}
  \end{center}
  \hrule height 2pt

  \begin{center}
    \large 
    María Carrasco Rodríguez \par 
    Francisco Manuel Herrero Pérez \par
    \vskip 15pt
    \hrule height 0.5pt
    \vskip 20pt
  \end{center}
  \begin{center}
    \small
    % \sffamily Universidad de Granada \par \vskip 1pt
    \sffamily Ingeniería del Conocimiento \par \vskip 1pt
    \footnotesize 
    \emph{Curso 09/10} \par
  \end{center}

  \vfil\null
\end{titlepage}


\tableofcontents

\pagebreak

\chapter{Introducción}
{\bf BattleTech} es un juego de combates entre enormes máquinas de
aspecto humanoide llamados {\it BattleMechs} (o más brevemente
llamados Mechs). \\
\begin{figure}[!h]
  \centering
  \includegraphics[width=7cm]{images/mech_super.jpg}
\end{figure}

\section{Descripción del Problema}
\begin{quote}
    {\it En la practica se ha de diseñar
    y desarrollar un prototipo de
    Jugador Inteligente. }
\end{quote}
\section{Abstracción del Problema}
La inteligencia artificia, {\bf IA}, es una disciplina relativamente
nueva, la cual es considerada como una gran desconocida y una de las
que más interés profano despierta. Pero, {¿qué es realmente la IA?}
Aunque existen muchas definiciones, podemos resumirlas en {\it
  ``desarrollar sistemas que piensen y actúen racionalmente''}.\\

También hemos encontrado otras definiciones que resultan interesantes:
\begin{itemize}
\item {\it `` The exciting new effort to make computers think ... machines
  with minds, in the full literal sense.''} (Haugeland, 1985)\\
\item {\it `` The art of creating machines that perform functions that
  require intelligence shen permormed by people''} (kurzweil, 1990)\\
\item {\it `` The study of how to make computers do things at which, at the
  moment people are better''} (Rich and Knight, 1991)\\
\end{itemize}
En la IA se encuentra un paradigma conocido como {\it ``paradigma de
  agentes''}, que aborda el desarrollo de entidades que puedan actuar
de forma autómata y razonada. Si retomamos la definición dada
anteriormente donde se consideraba a la IA como un medio para el
desarrollo de sistemas que piensen y actúen racionalmente, podemos
pensar que la IA, en su conjunto, trata realmente de construir
precisamente dichas entidades autónomas e inteligentes.
\begin{quote}
 ``Los agentes constituyen el próximo avance más significativo en el
 desarrollo de sistemas y pueden ser considerados como la nueva
 revolución en el software.''
 Dr. Nicholas Jennings
\end{quote}

\subsubsection{Agente Inteligente}
Un agente inteligente, es una entidad capaz de percibir su entorno,
procesar tales percepciones y responder o actuar en su entorno de
manera racional, es decir, de manera correcta y tendiendo a maximizar
un resultado esperado.\\

En este contexto la racionalidad es la característica que posee una
elección de ser correcta, más específicamente, de tender a maximizar
un resultado esperado. Este concepto de racionalidad es más general y
por ello más adecuado que inteligencia (la cual sugiere entendimiento)
para describir el comportamiento de los agentes inteligentes. Por este
motivo es mayor el consenso en llamarlos {\it agentes racionales}.\\

Nuestro {\bf jugador inteligente} se corresponde con un {\bf agente racional}, y
por lo tanto debe poseer las características:
\begin{itemize}
\item {\bf Reactivo.} El jugador podrá responder a cambios en el
  entorno en el que se encuentra situado. Estos cambios se le indican
  al jugador mediante los ficheros, que en cada fase de la partida el
  jugador debe leer para obtener toda la información necesaria.
\item {\bf Pro-activo.} El jugador debe ser capaz de intentar cumplir
  sus planes u objetivos. Su objetivo final será destruir a el resto
  de los jugadores.
\item {\bf Autonomía.} Nuestro agente actuará sin intervención de
  ningún usuario externo a nuestro programa. Por tanto tiene control
  total sobre sus acciones y estados internos.
\end{itemize}

\begin{figure}[!h]
  \centering
  \includegraphics[width=12.4cm]{images/funcion.png}
  \caption{Esquema de funcionamiento.}
\end{figure}
Hemos de diferenciar nuestro sistema de los sistemas Multi-Agente
(SMA). Éstos son grupos de agentes que interaccionan entre sí para
conseguir objetivos comunes, pero en nuestro entorno los distintos
jugadores no se comunican entre sí - no tienen conducta social-. Si
tuvieramos esto en cuenta, aumentaría la complejidad en el
desarrollo.\\

Nuestro agente es {\it basado en metas}. Estas ayudan a decidir las acciones
correctas en cada momento. En nuestro juego, el agente o jugador
escoge un objetivo, en base al cual toma sus decisiones. Por tanto, no
basta con conocer el entorno, sino además es necesario determinar las
acciones a seguir que permitan alcanzar la meta. Elegir las acciones
correctas varia en complejidad.
\begin{itemize}
\item {\it Búsqueda}
\item {\it Planificación}
\end{itemize}
\begin{figure}[!h]
  \centering
  \includegraphics[width=10cm]{images/metas.png}
  \caption{Agente basado en metas.}
\end{figure}
\subsubsection{Ambientes}
Existen diferentes tipos de ambientes:
\begin{itemize}
\item {\bf Accesibles y no accesibles.} En nuestro caso se trata de un
  ambiente accesible, ya que el agente tiene acceso al estado total
  del ambiente.
\item {\bf Deterministas y no deterministas.} Depende de si el estado
  siguiente se determina a partir del estado y las acciones elegidas
  por el agente.
\item {\bf Episódicos y no episódicos.} En ambientes episódicos, como
  es nuestro caso, la experiencia del agente se divide en
  ``episodios''- o fases-. Cada episodio consta de un agente que
  percibe y actúa.
\item {\bf Estáticos y dinámicos.} Si el abiente cambia mientras un
  agente toma una acción a seguir, entonces se dice que el ambiente es
  ``dinámico''. Pero en nuestro caso tratamos con ambientes {\it
    estáticos}, puesto que no se tiene que observar y pensar al mismo tiempo.
\item {\bf Discretos y continuos.} Si existe una cantidad limitada de
 percepciones y acciones distintas y discernibles, se dice que el
 ambiente es discreto. Si no es posible enumerarlos, entonces es un
 ambiente continuo. Nuestro problema abarca ambienes discretos, lo
 cual nos facilita el trabajo.
\end{itemize}

{\bf Programa de Ambientes.}\\

Un simulador toma como entrada uno o más agentes y dispone de lo
necesario para proporcionar las percepciones correctas una y otra vez
a cada agente y así recibir como respuesta una acción.\\

El simulador procede a actualizar  al ambiente tomando como base las
acciones, y posiblemente otros procesos dinámicos del ambiente que no
se consideran como agentes.\\

Los agentes se diseñan para que funcionen dentro de un conjunto de
ambientes diversos. Para poder medir el desempeño de un agente es
necesario contar con un simulador que seleccione ambientes
particulares en los que se pueda probar al agente.

\chapter{Modelo Teórico}

\chapter{Descripción de la Solución}

\section {Movimiento}

\subsection{Lógica del movimiento}
Uno de los mayores desafíos en el diseño de {\bf Inteligencia
  Artificial} realista en juegos de ordenador es el movimiento del
agente. Las estrategias de busqueda de caminos o {\it pathfinding} son
empleados como centro de los sistemas de movimiento.\\

Las estrategias de pathfinding debe encontrar un camino desde
cualquier coordenada del mundo hasta otra. Dados los puntos origen y
destino, encuentran intermedios que formen un camino a nuestro
destino. Para esto debemos tomar algún tipo de estructura de datos
para guiarnos en el movimiento. Esto nos lleva inevitablemente a
utilizar recursos de CPU, especialmente cuando buscamos un camino que
no existe.\\

De entre todos los algoritmos que se usan actualmente, el más conocido
y extensamente usado es el algoritmo A estrella {\bf A*}. \\

Veamos una comparación de tres tipos distintos de algoritmos.
\begin{figure}[!h]
  \centering
  \includegraphics[width=15cm]{images/images5.jpg}\label{comp}
  \caption{Comparación de algoritmos de búsqueda de caminos.}
\end{figure}

\begin{enumerate}
\item {\bf Djkstra}. Este algoritmo empieza visitando los vértices del
  grafo en el punto de partida. Luego va reiteradamente examinando los
  vértices mas cercanos que aún no hayan sido examinados. Se expando
  desde el nodo inicial hasta alcanzar el destino. Pero aunque esté
  garantizado encontrar una solución óptima, comprueba demasiadas
  casillas, por lo que hace un gasto de recursos enorme.\\
  Para una implementación simple, tenemos un tiempo de ejecución $O(n^2)$
\item {\bf Best First Search}. Es un algoritmo {\it Greedy} que
  trabaja de una forma simmilar al algoritmo de Dijkstra, aunque este
  presenta una ``heurística'' de como de lejos está nuestro
  objetivo. Aunque no nos garantice encontrar la solución óptima, si
  puede encontrar una solución apróximada en un tiempo mucho menor. El
  mayor inconveniente con este algoritmo es que intenta moverse hacia
  el objetivo aunque no sea el camino correcto -tal y como muestra la
  figura \ref{comp}. Esto es debido a que sólo tiene en cuenta el
  coste para llegar al objetivo, e ignora el coste del camino que
  lleva hasta ese momento. Entonces intentará seguir aunque el camino
  sea muy largo.\\
  El tiempo de ejecución es $O(n)$.
\item {\bf A*}. Este algoritmo fue desarrollado en 1968 para combinar
  enfoques heurísticos como en {\it Best First Searh} y enfoques
  formales como ocurre en {\it Dijkstra}. Aunque A* este enfocado
  construido sobre la heurística -y aunque esta no proporciona ninguna
  garantía-, A* puede garantizar el camino más corto.
\end{enumerate}

\subsection{Algoritmo A*}
El algoritmo de búsqueda A* es un tipo de algoritmo de búsqueda en
grafos. Se basa en encontrar, siempre y cuando se cumplan ciertas
condiciones, el camino de menor coste entre un nodo origen y uno
objetivo.\\

Nuestro objetivo es encontrar el camino más corto entre dos puntos
superando obstáculos (ya que en caso de que no hubiera obstáculos, es la
línea recta). Esta técnica muy usada en videojuegos de
estrategia y, en general en todos los videojuegos donde se trata la
inteligencia artificial. Por ello decidimos incorporarla a nuestra práctica.\\

La mayor ventaja de este algoritmo con respecto a otros es que tiene
en cuenta tanto el valor heurístico de los nodos como el coste real del
recorrido. Así, el algoritmo A* utiliza una función de evaluación:
$$f(n) = g(n) + h'(n) $$
Donde:
\begin {itemize}
\item {\bf h'(n)} Valor heurístico del nodo a evaluar desde el actual n
  hasta el final.
\item {\bf g(n)} Coste real del camino recorrido para llegar a dicho nodo, n.
\end {itemize}


A* mantiene dos estructuras de datos auxiliares:
\begin {itemize}
\item {\bf Abiertos}. Cola de prioridad, ordenada por el valor f(n) de
  cada nodo. (Lista de los nodos que necesitan ser comprobados)
\item {\bf Cerrados}. Guarda la información de los nodos que ya han
  sido visitados.
\end {itemize}
En cada paso del algoritmo se expande el nodo que esté primero en
abiertos, y en caso de que no sea un nodo objetivo, calcula la f(n) de
todos sus hijos, los inserta en abiertos, y pasa el nodo evaluado a cerrados.



\section {Implementación}
\begin{tabular}{  p{13cm}  }
  \hline    \hline                    
{\bf Algoritmo:} {\it A*. A estrella}\\  \hline     
{\bf Input:} {\it start}: Node de comienzo; {\it goal} Nodo final\\  \hline     
{\bf Output:} Lista con nodos que forman el camino (si existe).\\  \hline     

  \hline  \hline 
\begin{lstlisting}
  closed_set = {}
        
  start_node = start
  start_node.g_cost = 0
  start_node.f_cost = compute_f_cost(start_node, goal)
        
  open_set = PriorityQueueSet()
  open_set.add(start_node)
        
  while len(open_set) > 0:
     curr_node = open_set.pop_smallest()
            
     if curr_node.coord == goal:
        return reconstruct_path(curr_node)
            
     closed_set[curr_node] = curr_node
            
     for succ_coord in successors(curr_node.coord):
        succ_node = succ_coord
        succ_node.g_cost = compute_g_cost(curr_node, succ_node)
        succ_node.f_cost = compute_f_cost(succ_node, goal)
                
        if succ_node in closed_set:
           continue
                   
        if open_set.add(succ_node):
           succ_node.pred = curr_node
        
  return []
\end{lstlisting} 
\end{tabular}


La implementación es genérica y no se basa en ningún juego en
concreto. {\bf PathFinder} es una clase genérica que no tiene en
cuenta como representes tu grafo ni como representes o como calcules
el coste de moverte de un lugar a otro. Deja a gusto del programador
especificar la información mediante el paso de funciones al constructor.

\subsection{Pathfinder}
Esta clase implementa nuestro algorimo A*. Veamos ahora de que se compone.
\subsubsection{Sucesores o Hijos}

¿Cómo sabe {\it PathFinder} la forma de nuestro grafo? Sólo nos basta
con especificarlo en la función {\bf successors}. Esta función
especifica los sucesores de un node, que son aquellos nodos a los que
se puede llegar desde el nodo inicial en un solo paso. 

\begin{figure}[!h]
  \centering
  \includegraphics[width=7cm]{images/map2.png}
%  \caption{Trozo de mapa.}
\end{figure}

En nuestro ejemplo, los sucesores del nodo {\it 0103}, donde se encuentra
nuestro personaje, son: {\it 0102, 0202, 0203, 0104}

Ateniéndonos a las restricciones de {\it BattleTech}, vemos que
tenemos que tener en cuenta varias cosas:

\begin{itemize}
\item La diferencia de altura entre dos casillas colindantes no puede
  mayor a dos.
\item Si corremos, la profundidad del agua tiene que ser menor a uno.
\item En el caso de que andemos o corramos, debemos tener en cuenta si
  la casilla esta incendiada. En tal caso el fuego puede provocar un
  sobre calentamiento muy peligroso.
\item El el movimiento hacia atrás el máximo desnivel permitido es uno.
\end{itemize}

Para comprobar todos estos casos hacemos uso de la función {\bf
  checkCell(i,d, mov)}, donde {\bf i} es la casilla desde la que nos
queremos mover, {\bf d} es la casilla a la que nos queremos mover y {\bf mov} es
el tipo de movimiento a realizar.



\subsection{Función de evaluación}

\subsubsection{Función de coste}

{\it PathFinder} también conoce el coste de cada movimiento ya que se
lo estamos diciendo en la función {\bf move\_cost}. Esta función nos
dice el coste real para movernos de un nodo a otro. 

\subsubsection{Función heurística}

La última función que pasamos como argumento a {\it PathFinder} es
{\bf heuristic\_to\_goal}. Tal y como su nombre indica es la
heurística o coste del movimiento estimado para ir de un nodo origen a
un nodo destino.\\

Hay muchas formas de realizar esta función, la primera que utilizamos
es la {\bf distancia manhatan}.
$$ manhatan(x,y, x',y') = Vx + Vy $$
Siendo,
$$Vx = |x'-x| $$
$$Vy = |y'-y| $$

 Esta heurística no es completamente precisa, ya que  nos ofrece una
 sobreestimación del resultado correcto. Esto se debe a que la
 conectividad entre celdas es diferente en un mapa hexagonal que en
 uno rectangular, aunque la representación que hemos usado del mapa
 pueda invitar al error, ya que usamos una matriz cuadrada.\\

Finalmente, tras realizar varios experimentos con la función {\it
  manhattan}, nos dimos cuenta de que conducía a resultados erróneos
en un número elevado de ocasiones. Así, encontramos la función que nos
da la distancia exacta para un tablero hexagonal:
$$ hexagonal\_distance(x,y, x',y') = Vx + max \{0, Vy- (Vx/2) -
  factor\}  $$
Siendo:

$$ factor = \left \{ \begin{matrix} 0 & \mbox{if }mod(Vy,2) \ne 0 
\\ mod(x-1,2) & \mbox{if } y < y'
\\ mod(x'-1,2) & \mbox{otherwise } \end{matrix} \right. $$

De esta forma obtenemos la distancia real entre dos casillas de un tablero
hexagonal. Esto nos permite una mayor precisión en nuestros cálculos.

\subsection{Implementando la lista abierta}

Un aspecto interesante de implementación para mejorar la optimalidad
de nuestro programa es cómo implementar la lista de nodos
abiertos. Recordamos que A* usa la lista abierta para realizar un
seguimiento de los nodos que todavía tiene que vistar. Esta quizás sea
la estructura de datos más importante para el algoritmo, y su correcta
implementación es no trivial.\\

Aunque al principio empezamos con una implementación ineficiente de la
lista abierta, al decidir optimizar su implementación con una
estructura de datos más acertado mejoró cien veces su velocidad. Una
de las mejores fuentes de inspiración fueron las notas de
Amit.\ref{amit} \\

Combinando las colas de prioridad y las estructuras de datos tipo {\it
  set}, se consigue una cola de prioridad en la que sus componentes
están garantizados a ser únicos. \\

Esto nos proporciona una complejidad O(1) para pruebas de pertenencia,
y =(log N) para la extracción del menor elemento. La inserción en
cambio es mas complicada. Cuando un elemento no existe, se añade en
O(log N). En cambio, cuando ya existe, su prioridad se comprueba con
el nuevo elemento en O(1). Si la prioridad del nuevo elemento es
menor, se actualiza en la cola. Esto lleva un tiempo O(N).

\section{Reacción}
\section{Ataque con Armas}
\section{Ataque Físico}
\section{Final de Turno}

Esta fase nos brinda la posibilidad de apagar o encender radiadores,
soltar garrote o expulsar municiones.

\newpage
\begin{thebibliography}{XXX}
\bibitem{0} González Duque, R., 2003. {\it ``PYTHON para todos.''} $1^{st}$ed. \\
\bibitem{2} Gutschmidt, Tom, 2003. {\it ``Game Programming with Python,
    Lua, and Ruby.''  } Premier Press \\
\bibitem{2} Weixiong Zhang, 1999. {\it ``State-Space Search. Algorithms,
  Complexity, Extensions and Applications.''} Springer-Verlag: NY \\
\bibitem{3} Pilgrim, Mark, 2004. {\it ``Dive into Python.''} Apress. \\
\bibitem{1} Amit Patel\\ \url{
    http://theory.stanford.edu/~amitp/GameProgramming/} \label{amit}
  \\
\bibitem{0} Russell, S. \& Norvig, P. {\it ``Artificial Intelligence: A
    Modern Approach''} $3^{rd}$ed. \\ \label{russell}
\bibitem{4}  \url{http://www.policyalmanac.org/games/aStarTutorial.htm}\\
\bibitem{5}  \url{ }\\
\bibitem{6}  \url{ }\\
\bibitem{7}  \url{ }
\end{thebibliography}

\end{document}
